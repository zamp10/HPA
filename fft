%%cuda
#include <stdio.h>
#include <stdlib.h> // for rand() and srand()
#include <time.h>   // for time()

#define NUM_BINS 256 // Number of bins in the histogram
#define BLOCK_SIZE 256 // Threads per block

__global__ void computeHistogram(int *data, int *histogram, int size) {
    __shared__ int hist[NUM_BINS];

    // Initialize shared histogram bins to 0
    if (threadIdx.x < NUM_BINS) {
        hist[threadIdx.x] = 0;
    }
    __syncthreads();

    // Increment corresponding histogram bin
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    if (tid < size) {
        atomicAdd(&hist[data[tid]], 1);
    }
    __syncthreads();

    // Update global histogram
    if (threadIdx.x < NUM_BINS) {
        atomicAdd(&histogram[threadIdx.x], hist[threadIdx.x]);
    }
}

int main() {
    // Seed random number generator
    srand(time(NULL));

    // Define input data
    const int size = 10000; // Example size of input data
    int data[size];
    for (int i = 0; i < size; ++i) {
        data[i] = rand() % NUM_BINS; // Generate random data in the range [0, NUM_BINS-1]
    }

    // Allocate device memory for input data and histogram
    int *d_data, *d_histogram;
    cudaMalloc((void **)&d_data, size * sizeof(int));
    cudaMalloc((void **)&d_histogram, NUM_BINS * sizeof(int));

    // Copy input data to device
    cudaMemcpy(d_data, data, size * sizeof(int), cudaMemcpyHostToDevice);

    // Compute grid and block dimensions
    int numBlocks = (size + BLOCK_SIZE - 1) / BLOCK_SIZE;

    // Launch kernel
    computeHistogram<<<numBlocks, BLOCK_SIZE>>>(d_data, d_histogram, size);

    // Copy histogram from device to host
    int histogram[NUM_BINS];
    cudaMemcpy(histogram, d_histogram, NUM_BINS * sizeof(int), cudaMemcpyDeviceToHost);

    // Print histogram
    printf("Histogram:\n");
    for (int i = 0; i < NUM_BINS; ++i) {
        printf("%d: %d\n", i, histogram[i]);
    }

    // Free device memory
    cudaFree(d_data);
    cudaFree(d_histogram);

    return 0;
}
